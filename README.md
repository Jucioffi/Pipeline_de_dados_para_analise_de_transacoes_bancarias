# Pipeline de Dados para An√°lise de Transa√ß√µes Banc√°rias

Este reposit√≥rio cont√©m o desenvolvimento de um *Minimum Viable Product (MVP)* de engenharia de dados voltado √† an√°lise de transa√ß√µes banc√°rias, realizado como parte da p√≥s-gradua√ß√£o em Ci√™ncia de Dados na PUC-Rio.

O trabalho tem como foco a constru√ß√£o de um pipeline de dados em nuvem, contemplando as etapas de busca, coleta, modelagem, carga e an√°lise dos dados, utilizando a plataforma Databricks e o formato Delta Lake, seguindo a arquitetura Bronze‚ÄìSilver‚ÄìGold.

---

## Objetivo do Projeto

O objetivo do projeto √© desenvolver um pipeline anal√≠tico completo e reprodut√≠vel para dados transacionais banc√°rios, permitindo a explora√ß√£o de padr√µes de comportamento financeiro e operacional.

A partir do dataset utilizado, o trabalho busca responder perguntas como:
- Como os valores das transa√ß√µes se distribuem ao longo do tempo?
- Existem padr√µes distintos de acordo com o tipo de transa√ß√£o e o canal utilizado?
- Quais vari√°veis operacionais est√£o mais associadas ao volume financeiro movimentado?
- H√° ind√≠cios de risco operacional observ√°veis a partir das caracter√≠sticas das transa√ß√µes?

Mais do que responder a essas perguntas, o projeto busca demonstrar a aplica√ß√£o de boas pr√°ticas de engenharia de dados em ambiente de nuvem.

---

## Conjunto de Dados

O dataset utilizado √© p√∫blico e est√° dispon√≠vel neste reposit√≥rio:

- **Arquivo:** `bank_transactions_data_2.csv`
- **Formato:** CSV
- **Conte√∫do:** registros de transa√ß√µes banc√°rias com atributos financeiros, temporais, operacionais e demogr√°ficos.

O conjunto de dados n√£o cont√©m informa√ß√µes sens√≠veis ou identific√°veis de indiv√≠duos reais e √© utilizado exclusivamente para fins educacionais.

---

## Arquitetura do Pipeline

O pipeline foi estruturado seguindo a arquitetura **Bronze‚ÄìSilver‚ÄìGold**:

### üîπ Bronze (Raw)
- Ingest√£o dos dados brutos exatamente como fornecidos pela fonte.
- Persist√™ncia em formato Delta Lake.
- Preserva√ß√£o da integridade e rastreabilidade dos dados.

### üîπ Silver (Curated)
- Padroniza√ß√£o de tipos de dados.
- Tratamento de datas, valores num√©ricos e colunas categ√≥ricas.
- Cria√ß√£o de atributos derivados.
- Prepara√ß√£o dos dados para an√°lise e modelagem dimensional.

### üîπ Gold (Analytics)
- Modelagem dimensional em esquema estrela.
- Estrutura√ß√£o de tabelas fato e dimens√µes.
- Base pronta para an√°lises anal√≠ticas e explora√ß√£o de indicadores.

---

## Modelagem de Dados

A modelagem foi realizada no formato **Esquema Estrela**, composta por:
- Tabela fato de transa√ß√µes;
- Dimens√µes de tempo, tipo de transa√ß√£o, canal, categoria e usu√°rio.

Al√©m da modelagem, foi constru√≠do um **Cat√°logo de Dados**, contendo:
- descri√ß√£o dos atributos;
- tipos e dom√≠nios esperados;
- linhagem dos dados desde a fonte at√© as camadas anal√≠ticas.

---

## An√°lises Realizadas

A etapa de an√°lise foi dividida em dois grandes blocos:

### Qualidade de Dados
- Avalia√ß√£o de valores nulos, tipos inconsistentes e faixas inv√°lidas.
- Discuss√£o dos impactos desses problemas nas an√°lises.
- Valida√ß√£o da consist√™ncia dos dados ap√≥s o tratamento.

### Solu√ß√£o do Problema
- An√°lises explorat√≥rias orientadas √†s perguntas de neg√≥cio.
- Interpreta√ß√£o dos resultados √† luz do contexto transacional.
- Discuss√£o integrada dos achados, destacando o papel de vari√°veis operacionais e temporais.

---

## Desafios

Durante o desenvolvimento do projeto, foram identificadas restri√ß√µes t√©cnicas no **Databricks Community Edition**, tais como:
- Limita√ß√£o na leitura direta de arquivos via HTTP/HTTPS usando `spark.read.csv()`;
- Bloqueio de acesso ao sistema de arquivos local do driver;
- Desativa√ß√£o do DBFS p√∫blico (`/FileStore`).

Diante dessas restri√ß√µes, foi adotada uma solu√ß√£o t√©cnica baseada no uso de **Volumes (Unity Catalog)** como √°rea de aterrissagem (*landing zone*) dos dados. Essa abordagem permitiu manter o armazenamento em nuvem, garantir governan√ßa e assegurar a execu√ß√£o consistente do pipeline, transformando uma limita√ß√£o da plataforma em uma decis√£o arquitetural consciente.

---

## Tecnologias Utilizadas:

- Databricks Community Edition
- Apache Spark
- Delta Lake
- Python (PySpark)
- GitHub

---

## Considera√ß√µes Finais

O MVP desenvolvido atende aos requisitos propostos, demonstrando a constru√ß√£o de um pipeline de dados, documentado e alinhado √†s boas pr√°ticas de engenharia de dados em nuvem. A solu√ß√£o proposta estabelece uma base para futuras extens√µes, como a integra√ß√£o com ferramentas de visualiza√ß√£o, monitoramento em tempo real ou modelos anal√≠ticos mais avan√ßados.

---

## Autor

**J√∫lio Cioffi**  
Projeto desenvolvido como parte da p√≥s-gradua√ß√£o em Ci√™ncia de Dados ‚Äì PUC-Rio.

